import torch
import sounddevice as sd
import numpy as np
import io
import wave
import threading
import time
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import librosa
import queue

class SpeechToTextModule:
    def __init__(self,model_name = "vinai/PhoWhisper-medium",sample_rate = 16000, channels = 1, dtype = np.float32):
        # Kh·ªüi t·∫°o model PhoWhisper
        self.model_name = model_name
        self.processor = None
        self.model = None
        
        # Audio settings
        self.sample_rate = sample_rate
        self.channels = channels
        self.dtype = dtype
        
        # Recording state
        self.is_recording = False
        self.audio_data = []
        self.audio_queue = queue.Queue()
        
        print("ƒêang t·∫£i model...")
        self.load_model()
        print("T·∫£i th√†nh c√¥ng!")
        
    def load_model(self):
        """T·∫£i model v√† processor"""
        try:
            self.processor = WhisperProcessor.from_pretrained(self.model_name)
            self.model = WhisperForConditionalGeneration.from_pretrained(self.model_name)
            
            # Chuy·ªÉn model sang GPU n·∫øu c√≥
            if torch.cuda.is_available():
                self.model = self.model.cuda()
                print("ƒêang s·ª≠ d·ª•ng GPU")
            else:
                print("ƒêang s·ª≠ d·ª•ng CPU")
                
        except Exception as e:
            print(f"L·ªói khi t·∫£i model: {e}")
            raise
    
    def audio_callback(self, indata, frames, time, status):
        """Callback function ƒë·ªÉ ghi √¢m"""
        if status:
            print(f"Audio callback error: {status}")
        
        if self.is_recording:
            # Chuy·ªÉn ƒë·ªïi t·ª´ stereo sang mono n·∫øu c·∫ßn
            if indata.shape[1] > 1:
                audio_mono = np.mean(indata, axis=1)
            else:
                audio_mono = indata[:, 0]
            
            self.audio_queue.put(audio_mono.copy())
    
    def start_recording(self):
        """B·∫Øt ƒë·∫ßu ghi √¢m"""
        if self.is_recording:
            return
        
        print("B·∫Øt ƒë·∫ßu ghi...")
        self.is_recording = True
        self.audio_data = []
        
        # B·∫Øt ƒë·∫ßu stream audio
        self.stream = sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            dtype=self.dtype,
            callback=self.audio_callback
        )
        self.stream.start()
        
        # Thread ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu audio
        self.recording_thread = threading.Thread(target=self._collect_audio)
        self.recording_thread.start()
    
    def _collect_audio(self):
        """Thu th·∫≠p d·ªØ li·ªáu audio t·ª´ queue"""
        while self.is_recording:
            try:
                audio_chunk = self.audio_queue.get(timeout=0.1)
                self.audio_data.extend(audio_chunk)
            except queue.Empty:
                continue
    
    def stop_recording(self):
        """D·ª´ng ghi √¢m v√† tr·∫£ v·ªÅ audio data"""
        if not self.is_recording:
            return None
        
        print("D·ª´ng ghi...")
        self.is_recording = False
        
        # D·ª´ng stream
        self.stream.stop()
        self.stream.close()
        
        # ƒê·ª£i thread ghi √¢m k·∫øt th√∫c
        if hasattr(self, 'recording_thread'):
            self.recording_thread.join()
        
        # Thu th·∫≠p d·ªØ li·ªáu c√≤n l·∫°i trong queue
        while not self.audio_queue.empty():
            try:
                audio_chunk = self.audio_queue.get_nowait()
                self.audio_data.extend(audio_chunk)
            except queue.Empty:
                break
        
        if len(self.audio_data) > 0:
            return np.array(self.audio_data, dtype=np.float32)
        return None
    
    def transcribe_audio(self, audio_data):
        """Chuy·ªÉn ƒë·ªïi audio th√†nh text"""
        if audio_data is None or len(audio_data) == 0:
            return ""
        
        try:
            print("ƒêang chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i th√†nh vƒÉn b·∫£n...")
            
            # Chu·∫©n h√≥a audio v·ªÅ ƒë√∫ng sample rate
            if len(audio_data) < self.sample_rate * 0.1:  # Qu√° ng·∫Øn (< 0.1 gi√¢y)
                return ""
            
            # Ti·ªÅn x·ª≠ l√Ω audio
            input_features = self.processor(
                audio_data, 
                sampling_rate=self.sample_rate, 
                return_tensors="pt"
            ).input_features
            
            # Chuy·ªÉn sang GPU n·∫øu c√≥
            if torch.cuda.is_available():
                input_features = input_features.cuda()
            
            # T·∫°o token ids cho ti·∫øng Vi·ªát
            forced_decoder_ids = self.processor.get_decoder_prompt_ids(
                language="vi", 
                task="transcribe"
            )
            
            # Th·ª±c hi·ªán transcription
            with torch.no_grad():
                predicted_ids = self.model.generate(
                    input_features,
                    forced_decoder_ids=forced_decoder_ids,
                    max_length=448,
                    num_beams=5,
                    early_stopping=True
                )
            
            # Decode k·∫øt qu·∫£
            transcription = self.processor.batch_decode(
                predicted_ids, 
                skip_special_tokens=True
            )[0]
            
            print(f"K·∫øt qu·∫£: {transcription}")
            return transcription.strip()
            
        except Exception as e:
            print(f"L·ªói khi chuy·ªÉn ƒë·ªïi: {e}")
            return f"L·ªói: {str(e)}"
    
    def record_and_transcribe(self):
        """Ghi √¢m v√† chuy·ªÉn ƒë·ªïi trong m·ªôt l·∫ßn g·ªçi"""
        self.start_recording()
        input("Nh·∫•n Enter ƒë·ªÉ d·ª´ng ghi √¢m...")
        audio_data = self.stop_recording()
        return self.transcribe_audio(audio_data)



import tkinter as tk
from tkinter import ttk, scrolledtext

class SpeechToTextGUI:
    def __init__(self):
        self.stt_module = SpeechToTextModule()
        self.setup_gui()
        
    def setup_gui(self):
        """Thi·∫øt l·∫≠p giao di·ªán ng∆∞·ªùi d√πng"""
        self.root = tk.Tk()
        self.root.title("Speech to Text - PhoWhisper")
        self.root.geometry("500x400")
        
        # Frame ch√≠nh
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # N√∫t ghi √¢m
        self.record_button = ttk.Button(
            main_frame, 
            text="Nh·∫•n gi·ªØ ƒë·ªÉ ghi √¢m",
            style="Record.TButton"
        )
        self.record_button.grid(row=0, column=0, pady=10, sticky=(tk.W, tk.E))
        
        # Bind events cho n√∫t
        self.record_button.bind('<Button-1>', self.start_recording)
        self.record_button.bind('<ButtonRelease-1>', self.stop_recording)
        
        # Label tr·∫°ng th√°i
        self.status_label = ttk.Label(main_frame, text="S·∫µn s√†ng ghi √¢m")
        self.status_label.grid(row=1, column=0, pady=5)
        
        # Text area ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£
        ttk.Label(main_frame, text="K·∫øt qu·∫£:").grid(row=2, column=0, sticky=tk.W, pady=(10,5))
        
        self.result_text = scrolledtext.ScrolledText(
            main_frame, 
            height=15, 
            width=50,
            wrap=tk.WORD
        )
        self.result_text.grid(row=3, column=0, pady=5, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # N√∫t x√≥a
        clear_button = ttk.Button(main_frame, text="X√≥a", command=self.clear_text)
        clear_button.grid(row=4, column=0, pady=5)
        
        # Configure grid weights
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(3, weight=1)
        
        # Style cho n√∫t ghi √¢m
        style = ttk.Style()
        style.configure("Record.TButton", font=("Arial", 12, "bold"))
    
    def start_recording(self, event):
        """B·∫Øt ƒë·∫ßu ghi √¢m khi nh·∫•n n√∫t"""
        self.record_button.config(text="ƒêang ghi √¢m... (Th·∫£ ƒë·ªÉ d·ª´ng)", state="active")
        self.status_label.config(text="üî¥ ƒêang ghi √¢m...")
        self.root.update()
        
        self.stt_module.start_recording()
    
    def stop_recording(self, event):
        """D·ª´ng ghi √¢m khi th·∫£ n√∫t"""
        self.record_button.config(text="ƒêang x·ª≠ l√Ω...", state="disabled")
        self.status_label.config(text="‚è≥ ƒêang chuy·ªÉn ƒë·ªïi...")
        self.root.update()
        
        # D·ª´ng ghi √¢m v√† l·∫•y d·ªØ li·ªáu
        audio_data = self.stt_module.stop_recording()
        
        # Chuy·ªÉn ƒë·ªïi th√†nh text
        if audio_data is not None:
            transcription = self.stt_module.transcribe_audio(audio_data)
            if transcription:
                # Th√™m k·∫øt qu·∫£ v√†o text area
                self.result_text.insert(tk.END, transcription + "\n\n")
                self.result_text.see(tk.END)
        
        # Reset n√∫t v√† tr·∫°ng th√°i
        self.record_button.config(text="Nh·∫•n gi·ªØ ƒë·ªÉ ghi √¢m", state="normal")
        self.status_label.config(text="S·∫µn s√†ng ghi √¢m")
    
    def clear_text(self):
        """X√≥a n·ªôi dung text area"""
        self.result_text.delete(1.0, tk.END)
    
    def run(self):
        """Ch·∫°y ·ª©ng d·ª•ng"""
        print("·ª®ng d·ª•ng Speech to Text ƒë√£ s·∫µn s√†ng!")
        self.root.mainloop()


# S·ª≠ d·ª•ng module
if __name__ == "__main__":

    # Ch·∫°y v·ªõi giao di·ªán GUI
    app = SpeechToTextGUI()
    app.run()
    