## ğŸ› ï¸ Workflow Chi Tiáº¿t ToÃ n Bá»™ Há»‡ Thá»‘ng (Cáº­p nháº­t má»›i nháº¥t - LangGraph-based)

### 1. Luá»“ng Xá»­ LÃ½ Tá»•ng Thá»ƒ (LangGraph-based)
```mermaid
graph TD;
  A["User (Frontend - React)"] -->|"Send question + chat history via API /chat/stream"| B["Backend (FastAPI, LangGraph)"]
  B --> C0["LangGraph RAG Workflow"]
  C0 --> C1["set_intent: PhÃ¢n loáº¡i intent"]
  C1 --> C2["guardrails_input: Kiá»ƒm duyá»‡t an toÃ n Ä‘áº§u vÃ o (LlamaGuard)"]
  C2 --> C3["rewrite: LÃ m sáº¡ch, paraphrase cÃ¢u há»i vá»›i context"]
  C3 --> C4["semantic_cache: Kiá»ƒm tra cache semantic vá»›i cÃ¢u há»i Ä‘Ã£ rewrite"]
  
  C4 --> C5{Cache Hit?}
  C5 -->|YES| C6["Return cached answer + sources"]
  C5 -->|NO| C7["retrieve: Semantic Search (Qdrant, 4 collections, 25 candidates)"]
  
  C7 --> C8["generate: Táº¡o prompt Ä‘á»™ng + gá»i LLM (AWS Bedrock)"]
  C8 --> C9["validate: Kiá»ƒm duyá»‡t Ä‘áº§u ra (LlamaGuard Output)"]
  C9 --> C10["update_memory: Cáº­p nháº­t lá»‹ch sá»­ há»™i thoáº¡i"]
  C10 --> D["Supabase (PostgreSQL): Store chat history, metadata"]
  
  C6 --> E["Stream cached answer + sources to Frontend"]
  C8 --> F["Stream answer chunks + sources to Frontend"]
  
  E --> A
  F --> A
```

### 2. MÃ´ táº£ chi tiáº¿t tá»«ng bÆ°á»›c

**A. Frontend (React 18)**
- NgÆ°á»i dÃ¹ng nháº­p cÃ¢u há»i vÃ  gá»­i request qua API `/chat/stream`.
- Gá»­i kÃ¨m máº£ng `messages` chá»©a lá»‹ch sá»­ há»™i thoáº¡i.
- **Nháº­n káº¿t quáº£ tráº£ vá» dáº¡ng streaming:**
  - CÃ¡c chunk `"type": "chunk"` chá»©a ná»™i dung tráº£ lá»i.
  - Chunk `"type": "sources"` chá»©a metadata nguá»“n tham kháº£o (bao gá»“m cáº£ file máº«u, link táº£i vá»...).
- **Hiá»ƒn thá»‹:**
  - Ná»™i dung tráº£ lá»i.
  - Náº¿u cÃ³ file máº«u trong sources, **hiá»‡n nÃºt táº£i vá» ná»•i báº­t** phÃ­a dÆ°á»›i.
  - Khi báº¥m "Hiá»‡n nguá»“n tham kháº£o", hiá»ƒn thá»‹ Ä‘Ãºng thÃ´ng tin nguá»“n (luáº­t hoáº·c biá»ƒu máº«u, cÃ³ link táº£i náº¿u lÃ  máº«u).

**B. Backend (FastAPI + LangGraph)**
- Nháº­n request, sinh `session_id` náº¿u chÆ°a cÃ³, chuáº©n hÃ³a lá»‹ch sá»­ há»™i thoáº¡i.
- **LangGraph RAG Workflow:**

#### BÆ°á»›c 1-4: Xá»­ lÃ½ chung
1. **set_intent:** PhÃ¢n loáº¡i intent (law, form, term, procedure, template, ambiguous).
2. **guardrails_input:** Kiá»ƒm duyá»‡t an toÃ n Ä‘áº§u vÃ o (LlamaGuard Input). Náº¿u vi pháº¡m, tráº£ vá» thÃ´ng bÃ¡o an toÃ n.
3. **rewrite:** LÃ m sáº¡ch, paraphrase cÃ¢u há»i vá»›i context tá»« lá»‹ch sá»­ há»™i thoáº¡i (rule-based + LLM náº¿u cáº§n).
4. **semantic_cache:** Kiá»ƒm tra cache semantic vá»›i cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c rewrite.

#### NhÃ¡nh A: Cache Hit (TrÃ¹ng cache)
**Khi tÃ¬m tháº¥y cÃ¢u há»i tÆ°Æ¡ng tá»± trong cache:**
- **Láº¥y káº¿t quáº£ cache:** TrÃ­ch xuáº¥t answer vÃ  sources tá»« cache
- **Cáº­p nháº­t metadata:** Ghi log cache hit, thá»i gian xá»­ lÃ½
- **Stream káº¿t quáº£:** Gá»­i cached answer vÃ  sources vá» frontend
- **Bá» qua cÃ¡c bÆ°á»›c:** KhÃ´ng cáº§n retrieve, generate, validate
- **LÆ°u lá»‹ch sá»­:** Váº«n lÆ°u vÃ o Supabase Ä‘á»ƒ tracking

#### NhÃ¡nh B: Cache Miss (KhÃ´ng trÃ¹ng cache)
**Khi khÃ´ng tÃ¬m tháº¥y cÃ¢u há»i tÆ°Æ¡ng tá»± trong cache:**
5. **retrieve:** TÃ¬m kiáº¿m semantic trong cÃ¡c collection tÆ°Æ¡ng á»©ng (top 25).
6. **generate:** Táº¡o prompt Ä‘á»™ng phÃ¹ há»£p intent, chÃ¨n context vÃ  metadata.
7. **validate:** Kiá»ƒm duyá»‡t Ä‘áº§u ra (LlamaGuard Output).
8. **update_memory:** LÆ°u láº¡i cÃ¢u há»i, cÃ¢u tráº£ lá»i, nguá»“n, intent, v.v. vÃ o Supabase.
9. **Cache káº¿t quáº£:** LÆ°u káº¿t quáº£ má»›i vÃ o semantic cache cho láº§n sau.

### 3. SÆ¡ Äá»“ Luá»“ng Dá»¯ Liá»‡u Chi Tiáº¿t (Data Flow, LangGraph-based)

```mermaid
sequenceDiagram
    participant U as User (Frontend)
    participant B as Backend (FastAPI + LangGraph)
    participant L as LangGraph Workflow
    participant Q as Qdrant (Vector DB)
    participant LLM as AWS Bedrock (LLM)
    participant S as Supabase (PostgreSQL)
    participant C as Cache Service
    
    U->>B: POST /chat/stream (question + messages)
    B->>L: set_intent
    L->>L: guardrails_input
    L->>L: rewrite (vá»›i context tá»« lá»‹ch sá»­)
    L->>L: semantic_cache (vá»›i cÃ¢u há»i Ä‘Ã£ rewrite)
    L->>C: Check semantic cache vá»›i rewritten query
    
    alt Cache HIT (TrÃ¹ng cache)
        C-->>L: Cached answer + sources
        L->>L: update_memory (lÆ°u lá»‹ch sá»­)
        L->>S: LÆ°u chat history vá»›i cache flag
        L-->>B: Cached answer + sources
        B-->>U: Stream cached answer chunks + sources
        Note over C: Cache hit - Fast response
        
    else Cache MISS (KhÃ´ng trÃ¹ng cache)
        L->>L: retrieve
        L->>Q: Semantic search (4 collections)
        Q-->>L: Top 25 candidates
        L->>L: generate
        L->>LLM: Generate answer (streaming)
        LLM-->>L: Answer chunks
        L->>L: validate
        L->>L: update_memory
        L->>S: LÆ°u lá»‹ch sá»­ chat, log
        L->>C: Cache káº¿t quáº£ má»›i
        L-->>B: Tráº£ answer + sources
        B-->>U: Stream answer chunks + sources
        Note over C: Cache miss - Full processing
    end
```

### 4. Chi Tiáº¿t Xá»­ LÃ½ Cache Hit vs Cache Miss

#### ğŸ”„ **Cache Hit Scenario:**
```json
{
  "processing_flow": "cache_hit",
  "steps_executed": ["set_intent", "guardrails_input", "rewrite", "semantic_cache"],
  "cache_data": {
    "original_query": "LÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘Äƒng kÃ½ thÆ°á»ng trÃº?",
    "rewritten_query": "LÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘Äƒng kÃ½ thÆ°á»ng trÃº theo quy Ä‘á»‹nh hiá»‡n hÃ nh?",
    "cached_answer": "Äá»ƒ Ä‘Äƒng kÃ½ thÆ°á»ng trÃº, báº¡n cáº§n...",
    "cached_sources": [...],
    "cache_timestamp": "2024-01-15T10:30:00Z",
    "similarity_score": 0.95
  },
  "performance_metrics": {
    "total_processing_time": "0.2s",
    "cache_lookup_time": "0.05s",
    "saved_processing_time": "3.8s"
  }
}
```

#### âš¡ **Cache Miss Scenario:**
```json
{
  "processing_flow": "cache_miss",
  "steps_executed": ["set_intent", "guardrails_input", "rewrite", "semantic_cache", "retrieve", "generate", "validate", "update_memory"],
  "processing_details": {
    "intent": "procedure",
    "confidence": 0.89,
    "collections_searched": ["procedure_chunks", "legal_chunks"],
    "documents_retrieved": 25,
    "documents_reranked": 8,
    "llm_model": "llama-4-scout-17b",
    "prompt_tokens": 2048,
    "response_tokens": 512
  },
  "performance_metrics": {
    "total_processing_time": "4.2s",
    "retrieval_time": "0.8s",
    "generation_time": "2.5s",
    "validation_time": "0.3s"
  }
}
```

### 5. Cáº¥u trÃºc dá»¯ liá»‡u vÃ  API

**ChatRequest:**
```json
{
  "question": "string",
  "session_id": "string (optional)",
  "messages": [
    {"role": "user|assistant", "content": "string"}
  ]
}
```

**Streaming Response:**
```json
// Chunk ná»™i dung
{"type": "chunk", "content": "string"}

// Sources metadata
{"type": "sources", "sources": [
  {
    "title": "string",
    "code": "string",
    "file_url": "string",
    "url": "string",
    "content": "string",
    "metadata": {}
  }
]}

// Káº¿t thÃºc
{"type": "done"}
```

### 6. Chi tiáº¿t xá»­ lÃ½ sources

- **Backend:**
  - Khi truy váº¥n liÃªn quan Ä‘áº¿n biá»ƒu máº«u, backend láº¥y metadata (file_url, code, title, ...) tá»« Qdrant hoáº·c nguá»“n dá»¯ liá»‡u.
  - Sau khi stream xong ná»™i dung tráº£ lá»i, backend gá»­i chunk `{"type": "sources", "sources": [...]}` cho frontend.
- **Frontend:**
  - Khi nháº­n chunk `type: sources`, frontend gÃ¡n vÃ o message bot cuá»‘i cÃ¹ng.
  - Component Message.js sáº½ tá»± Ä‘á»™ng hiá»ƒn thá»‹ nÃºt táº£i vá» náº¿u cÃ³ file_url, vÃ  hiá»ƒn thá»‹ nguá»“n tham kháº£o Ä‘Ãºng loáº¡i (luáº­t, biá»ƒu máº«u, ...).

### 7. Tá»‘i Æ¯u HÃ³a Hiá»‡u Suáº¥t

#### ğŸš€ **Cache Hit Benefits:**
- **Thá»i gian pháº£n há»“i:** Giáº£m tá»« ~4s xuá»‘ng ~0.2s
- **Tiáº¿t kiá»‡m tÃ i nguyÃªn:** KhÃ´ng cáº§n gá»i LLM vÃ  search
- **Tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng:** Pháº£n há»“i nhanh hÆ¡n
- **Chi phÃ­:** Giáº£m chi phÃ­ API calls

#### ğŸ“Š **Cache Miss Processing:**
- **Full RAG pipeline:** Cháº¡y Ä‘áº§y Ä‘á»§ 8 bÆ°á»›c
- **Semantic search:** TÃ¬m kiáº¿m trong 4 collections
- **LLM generation:** Táº¡o cÃ¢u tráº£ lá»i má»›i
- **Quality assurance:** Validate an toÃ n
- **Cache storage:** LÆ°u káº¿t quáº£ cho láº§n sau

### 8. TÃ³m táº¯t cÃ¡c Ä‘iá»ƒm má»›i ná»•i báº­t

- **Backend luÃ´n tráº£ vá» sources (bao gá»“m file_url, code, title...) trong chunk riÃªng biá»‡t.**
- **Frontend tá»± Ä‘á»™ng nháº­n sources vÃ  render nÃºt táº£i vá» máº«u, hiá»ƒn thá»‹ nguá»“n tham kháº£o Ä‘Ãºng loáº¡i (luáº­t, biá»ƒu máº«u...).**
- **KhÃ´ng cÃ²n link dÃ i ngoáº±ng trong ná»™i dung tráº£ lá»i.**
- **UX tá»‘t hÆ¡n, ngÆ°á»i dÃ¹ng dá»… dÃ ng táº£i file máº«u vÃ  xem nguá»“n tham kháº£o.**
- **LangGraph workflow vá»›i 8 bÆ°á»›c xá»­ lÃ½ tuáº§n tá»±.**
- **Streaming thá»±c sá»± tá»« AWS Bedrock LLM.**
- **Semantic cache vá»›i cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c rewrite Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t.**
- **Guardrails an toÃ n Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra.**
- **Xá»­ lÃ½ thÃ´ng minh cho cache hit/miss vá»›i performance metrics chi tiáº¿t.**


