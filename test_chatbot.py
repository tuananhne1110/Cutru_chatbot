#!/usr/bin/env python3
"""
Test script cho chatbot v·ªõi AWS Bedrock
"""

import asyncio
import logging
from agents.langgraph_implementation import create_rag_workflow, create_initial_state
from langchain_core.runnables import RunnableConfig
from typing import cast

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_chatbot():
    """Test chatbot v·ªõi AWS Bedrock"""
    
    # T·∫°o workflow
    rag_workflow = create_rag_workflow()
    
    # Test questions
    test_questions = [
        "Xin ch√†o, b·∫°n c√≥ th·ªÉ gi√∫p t√¥i t√¨m hi·ªÉu v·ªÅ th·ªß t·ª•c ƒëƒÉng k√Ω t·∫°m tr√∫ kh√¥ng?",
        "Th·∫ø n√†o l√† th∆∞·ªùng tr√∫?",
        "H∆∞·ªõng d·∫´n ƒëi·ªÅn m·∫´u CT01",
        "ƒêi·ªÅu 20 Lu·∫≠t C∆∞ tr√∫ quy ƒë·ªãnh g√¨?"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*60}")
        print(f"TEST {i}: {question}")
        print(f"{'='*60}")
        
        try:
            # T·∫°o initial state
            session_id = f"test_session_{i}"
            initial_state = create_initial_state(question, [], session_id)
            
            # Run workflow
            config = cast(RunnableConfig, {"configurable": {"thread_id": session_id}})
            result = await rag_workflow.ainvoke(initial_state, config=config)
            
            # Extract results
            answer = result.get("answer", "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi")
            sources = result.get("sources", [])
            intent = result.get("intent", "unknown")
            processing_time = result.get("processing_time", {})
            
            print(f"Intent: {intent}")
            print(f"Answer: {answer}")
            print(f"Sources: {len(sources)} sources found")
            print(f"Processing time: {processing_time}")
            
            if sources:
                print("\nTop sources:")
                for j, source in enumerate(sources[:2], 1):
                    print(f"  {j}. {source.get('title', 'N/A')}")
                    print(f"     Content: {source.get('content', 'N/A')[:100]}...")
            
        except Exception as e:
            print(f"Error: {e}")
            logger.error(f"Error in test {i}: {e}")

def test_llm_direct():
    """Test LLM service tr·ª±c ti·∫øp"""
    print("\n" + "="*60)
    print("TESTING LLM SERVICE DIRECTLY")
    print("="*60)
    
    try:
        from services.llm_service import call_llm_full
        
        test_prompt = "Xin ch√†o, b·∫°n c√≥ th·ªÉ gi√∫p t√¥i t√¨m hi·ªÉu v·ªÅ th·ªß t·ª•c ƒëƒÉng k√Ω t·∫°m tr√∫ kh√¥ng?"
        
        print(f"Testing prompt: {test_prompt}")
        result = call_llm_full(test_prompt, "llama")
        print(f"Response: {result}")
        
    except Exception as e:
        print(f"Error testing LLM: {e}")

if __name__ == "__main__":
    print("üöÄ Testing Chatbot with AWS Bedrock")
    print("="*60)
    
    # Test LLM tr·ª±c ti·∫øp tr∆∞·ªõc
    test_llm_direct()
    
    # Test chatbot workflow
    print("\n" + "="*60)
    print("TESTING CHATBOT WORKFLOW")
    print("="*60)
    
    asyncio.run(test_chatbot())
    
    print("\n‚úÖ Testing completed!") 